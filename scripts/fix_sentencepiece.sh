# fix_sentencepiece.sh
# Fix SentencePiece installation for T5 tokenizer

echo "ğŸ”§ Fixing SentencePiece installation..."

# Activate virtual environment
source venv/bin/activate

# Install SentencePiece
echo "ğŸ“¦ Installing SentencePiece..."
pip install sentencepiece==0.1.99

# Install protobuf (sometimes needed)
echo "ğŸ“¦ Installing protobuf..."
pip install protobuf==4.25.1

# Alternative: Install specific transformers tokenizers
echo "ğŸ“¦ Installing tokenizers..."
pip install tokenizers==0.20.0

# Test the installation
echo "ğŸ§ª Testing SentencePiece installation..."
python -c "
try:
    import sentencepiece
    print('âœ… SentencePiece installed successfully!')
    print(f'   Version: {sentencepiece.__version__}')
except ImportError as e:
    print(f'âŒ SentencePiece import failed: {e}')

try:
    from transformers import T5Tokenizer
    tokenizer = T5Tokenizer.from_pretrained('t5-small')
    print('âœ… T5Tokenizer working!')
except Exception as e:
    print(f'âŒ T5Tokenizer failed: {e}')
"

echo "ğŸ¯ SentencePiece fix complete!"